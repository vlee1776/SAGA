{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A familiar dataset which I've played with and have parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (768, 8)\n",
      "Shape of y: (768,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy\n",
    "\n",
    "x_sparse, y = datasets.load_svmlight_file('diabetes')\n",
    "x = x_sparse.todense()\n",
    "\n",
    "print('Shape of x: ' + str(x.shape))\n",
    "print('Shape of y: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 8)\n",
      "Shape of x_test: (128, 8)\n",
      "Shape of y_train: (640, 1)\n",
      "Shape of y_test: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "# partition the data to training and test sets\n",
    "n = x.shape[0]\n",
    "n_train = 640\n",
    "n_test = n - n_train\n",
    "\n",
    "rand_indices = numpy.random.permutation(n)\n",
    "train_indices = rand_indices[0:n_train]\n",
    "test_indices = rand_indices[n_train:n]\n",
    "\n",
    "x_train = x[train_indices, :]\n",
    "x_test = x[test_indices, :]\n",
    "y_train = y[train_indices].reshape(n_train, 1)\n",
    "y_test = y[test_indices].reshape(n_test, 1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean = \n",
      "[[-0.04785122 -0.12557859  0.05500977  0.05743532 -0.02749454  0.04597634\n",
      "   0.09983854  0.16046459]]\n",
      "test std = \n",
      "[[1.00633571 0.89920662 1.05102339 0.95716193 1.04239613 0.9975458\n",
      "  0.91969456 1.10635728]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "import numpy\n",
    "\n",
    "# calculate mu and sig using the training set\n",
    "d = x_train.shape[1]\n",
    "mu = numpy.mean(x_train, axis=0).reshape(1, d)\n",
    "sig = numpy.std(x_train, axis=0).reshape(1, d)\n",
    "\n",
    "# transform the training features\n",
    "x_train = (x_train - mu) / (sig + 1E-6)\n",
    "\n",
    "# transform the test features\n",
    "x_test = (x_test - mu) / (sig + 1E-6)\n",
    "\n",
    "print('test mean = ')\n",
    "print(numpy.mean(x_test, axis=0))\n",
    "\n",
    "print('test std = ')\n",
    "print(numpy.std(x_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 9)\n",
      "Shape of x_test: (128, 9)\n"
     ]
    }
   ],
   "source": [
    "n_train, d = x_train.shape\n",
    "x_train = numpy.concatenate((x_train, numpy.ones((n_train, 1))), axis=1)\n",
    "\n",
    "n_test, d = x_test.shape\n",
    "x_test = numpy.concatenate((x_test, numpy.ones((n_test, 1))), axis=1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SAGA for logistic loss\n",
    "\n",
    "No regularizer in the loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic loss objective value \n",
    "# y: scalar \n",
    "# x: 1 by d vector \n",
    "# w: d by 1 vector\n",
    "def logistic_loss(y,x,w):\n",
    "    exponent = float(numpy.exp(-y * numpy.dot(x,w))) # scalar\n",
    "    objective = numpy.log(1 + exponent) \n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient of logisitic loss\n",
    "# y: scalar \n",
    "# x: 1 by d vector \n",
    "# w: d by 1 vector\n",
    "def logistic_gradient(y,x,w):\n",
    "    exponent = float(numpy.exp(y * numpy.dot(x,w))) # scalar\n",
    "    derivative = (-y * x).T / (1 + exponent) # d by 1\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAGA with $l2$ norm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: training set, n by d \n",
    "# y: training labels, n by 1 \n",
    "# lam: l2 norm regularization\n",
    "def saga_l2(X,y,lam, step_size,max_epochs,proximal,obj_func,grad_func):\n",
    "    obj_vals = []\n",
    "    n, d = X.shape  \n",
    "    w = numpy.zeros((d,1))\n",
    "    derivatives = numpy.zeros((n,d))\n",
    "    # initialize table with derivative w/weight 0\n",
    "    for i in range(d):\n",
    "        derivatives[i,:] = grad_func(y[i],X[i,:],w).reshape(9,)\n",
    "        \n",
    "    for epoch in range(max_epochs):\n",
    "        permutation = numpy.random.permutation(n)\n",
    "        X_shuffled = X[permutation,:]\n",
    "        y_shuffled = y[permutation,:]\n",
    "        obj_epoch = 0\n",
    "        for i in range(n):\n",
    "            xi = X_shuffled[i,:]\n",
    "            yi = y_shuffled[i]\n",
    "            \n",
    "            updated_deriv = grad_func(yi,xi,w) # d by 1\n",
    "            derivatives[permutation[i],:] = updated_deriv.reshape(d) \n",
    "            previous_deriv = derivatives[permutation[i],:].reshape((d,1)) # d by 1\n",
    "            table_avg = numpy.mean(derivatives,axis=0).reshape((d,1))\n",
    "            update = updated_deriv - previous_deriv + table_avg\n",
    "            w = (1-step_size*lam) * w - (step_size * update)\n",
    "            w = proximal(w)\n",
    "            obj_iter = obj_func(y_shuffled[i],X_shuffled[i,:],w)\n",
    "            obj_epoch += obj_iter\n",
    "        obj_epoch /= n\n",
    "        obj_vals.append(obj_epoch)\n",
    "        print(\"Obj val at epoch \" + str(epoch) + ' is ' + str(obj_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h(x) = 0\n",
    "def proximal(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obj val at epoch 0 is 0.6612772064254964\n",
      "Obj val at epoch 1 is 0.5567893702877738\n",
      "Obj val at epoch 2 is 0.51582944864235\n",
      "Obj val at epoch 3 is 0.5011042114342608\n",
      "Obj val at epoch 4 is 0.4908513274020966\n",
      "Obj val at epoch 5 is 0.48746501185642827\n",
      "Obj val at epoch 6 is 0.48432366120333825\n",
      "Obj val at epoch 7 is 0.4824687919427225\n",
      "Obj val at epoch 8 is 0.4811736841593891\n",
      "Obj val at epoch 9 is 0.48034575290768355\n",
      "Obj val at epoch 10 is 0.47967347219603934\n",
      "Obj val at epoch 11 is 0.4794622071492786\n",
      "Obj val at epoch 12 is 0.4789443990543848\n",
      "Obj val at epoch 13 is 0.4787026487686383\n",
      "Obj val at epoch 14 is 0.4786254227387948\n",
      "Obj val at epoch 15 is 0.47839203129431607\n",
      "Obj val at epoch 16 is 0.4784159643668195\n",
      "Obj val at epoch 17 is 0.4783023778924946\n",
      "Obj val at epoch 18 is 0.47826962176136567\n",
      "Obj val at epoch 19 is 0.47822786412359986\n",
      "Obj val at epoch 20 is 0.4782081872847647\n",
      "Obj val at epoch 21 is 0.47818824941895777\n",
      "Obj val at epoch 22 is 0.47816676700567673\n",
      "Obj val at epoch 23 is 0.47819707456297705\n",
      "Obj val at epoch 24 is 0.47816840911748437\n",
      "Obj val at epoch 25 is 0.478150972943651\n",
      "Obj val at epoch 26 is 0.4781728048780174\n",
      "Obj val at epoch 27 is 0.47815119819333124\n",
      "Obj val at epoch 28 is 0.4781412898407068\n",
      "Obj val at epoch 29 is 0.4781404250788291\n",
      "Obj val at epoch 30 is 0.4781419079572484\n",
      "Obj val at epoch 31 is 0.4781366946655344\n",
      "Obj val at epoch 32 is 0.4781335428579692\n",
      "Obj val at epoch 33 is 0.47813766875394625\n",
      "Obj val at epoch 34 is 0.47813243281296447\n",
      "Obj val at epoch 35 is 0.4781344490636911\n",
      "Obj val at epoch 36 is 0.47813592090574764\n",
      "Obj val at epoch 37 is 0.4781321689625201\n",
      "Obj val at epoch 38 is 0.4781337675650815\n",
      "Obj val at epoch 39 is 0.4781317315954291\n",
      "Obj val at epoch 40 is 0.4781348224119246\n",
      "Obj val at epoch 41 is 0.4781311012728743\n",
      "Obj val at epoch 42 is 0.4781339533909816\n",
      "Obj val at epoch 43 is 0.4781325445607575\n",
      "Obj val at epoch 44 is 0.4781339667076098\n",
      "Obj val at epoch 45 is 0.4781325470079324\n",
      "Obj val at epoch 46 is 0.4781331997928291\n",
      "Obj val at epoch 47 is 0.47813259998314644\n",
      "Obj val at epoch 48 is 0.4781332750736794\n",
      "Obj val at epoch 49 is 0.4781335539349366\n",
      "Obj val at epoch 50 is 0.47813305298397824\n",
      "Obj val at epoch 51 is 0.47813321139119525\n",
      "Obj val at epoch 52 is 0.47813327033686\n",
      "Obj val at epoch 53 is 0.4781331582501841\n",
      "Obj val at epoch 54 is 0.47813301455010426\n",
      "Obj val at epoch 55 is 0.47813364929654883\n",
      "Obj val at epoch 56 is 0.47813330277090094\n",
      "Obj val at epoch 57 is 0.47813322283125403\n",
      "Obj val at epoch 58 is 0.4781331813300526\n",
      "Obj val at epoch 59 is 0.4781332076985036\n",
      "Obj val at epoch 60 is 0.4781331045728804\n",
      "Obj val at epoch 61 is 0.47813330009734595\n",
      "Obj val at epoch 62 is 0.4781332433316699\n",
      "Obj val at epoch 63 is 0.47813316614492674\n",
      "Obj val at epoch 64 is 0.47813309448501906\n",
      "Obj val at epoch 65 is 0.4781332971417337\n",
      "Obj val at epoch 66 is 0.47813316183886795\n",
      "Obj val at epoch 67 is 0.47813317488213675\n",
      "Obj val at epoch 68 is 0.47813316033758746\n",
      "Obj val at epoch 69 is 0.4781331646385267\n",
      "Obj val at epoch 70 is 0.4781331776799373\n",
      "Obj val at epoch 71 is 0.47813316249868637\n",
      "Obj val at epoch 72 is 0.4781331549381928\n",
      "Obj val at epoch 73 is 0.47813317598576266\n",
      "Obj val at epoch 74 is 0.478133181606457\n",
      "Obj val at epoch 75 is 0.4781331750912269\n",
      "Obj val at epoch 76 is 0.4781331785657811\n",
      "Obj val at epoch 77 is 0.4781331844187219\n",
      "Obj val at epoch 78 is 0.47813316593618105\n",
      "Obj val at epoch 79 is 0.47813318973584773\n",
      "Obj val at epoch 80 is 0.4781331956368281\n",
      "Obj val at epoch 81 is 0.47813319274980265\n",
      "Obj val at epoch 82 is 0.478133183515762\n",
      "Obj val at epoch 83 is 0.47813318713551245\n",
      "Obj val at epoch 84 is 0.47813318365565943\n",
      "Obj val at epoch 85 is 0.47813317931239024\n",
      "Obj val at epoch 86 is 0.4781331839478285\n",
      "Obj val at epoch 87 is 0.4781331911254614\n",
      "Obj val at epoch 88 is 0.4781331831549645\n",
      "Obj val at epoch 89 is 0.4781331827875489\n",
      "Obj val at epoch 90 is 0.47813317766610836\n",
      "Obj val at epoch 91 is 0.4781331826031952\n",
      "Obj val at epoch 92 is 0.478133184113455\n",
      "Obj val at epoch 93 is 0.47813318038981373\n",
      "Obj val at epoch 94 is 0.47813318086564055\n",
      "Obj val at epoch 95 is 0.4781331827484065\n",
      "Obj val at epoch 96 is 0.47813318255509263\n",
      "Obj val at epoch 97 is 0.47813318101285096\n",
      "Obj val at epoch 98 is 0.47813318176980896\n",
      "Obj val at epoch 99 is 0.47813318369149915\n"
     ]
    }
   ],
   "source": [
    "_,eigs,_ = numpy.linalg.svd(x_train * x_train.T)\n",
    "n,d = numpy.shape(x_train)\n",
    "alpha = 1E-6\n",
    "step_size = 1 / (n * alpha + 1/4 * eigs[0])\n",
    "saga_l2(x_train,y_train,alpha,step_size,100,proximal,logistic_loss,logistic_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
